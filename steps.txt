1] cd $HADOOP_HOME -> ./sbin/start-all.sh
2] cd $SPARK_HOME ->  ./sbin/start-all.sh
3] cd $KAFKA_HOME  -> ./bin/zookeeper-server-start.sh config/zookeeper.properties
{or cd /usr/local/kafka} -> ./bin/kafka-server-start.sh config/server.properties

4] cd $SPARK_HOME   -> 
                       ./bin/spark-submit --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.4.0 --driver-class-path /usr/share/java/mysql-connector-java-8.2.0.jar --jars /usr/share/java/mysql-connector-java-8.2.0.jar /home/rachana/Stream-Processing-and-Batch-Processing-Using-Streaming-Spark-and-Kafka/kafka_read.py 2> /home/rachana/Stream-Processing-and-Batch-Processing-Using-Streaming-Spark-and-Kafka/Output/error.txt
along with running producer.py and kafka_read.py

5] then delete the topics from kafka and then do stream processing

6]Go to the directory containing producer.py
Run this in another console: python3 produce_tweet.py
                            python3 consumer_stream.py
7]for bacth processing: ./bin/spark-submit --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.4.0 --driver-class-path /usr/share/java/mysql-connector-java-8.2.0.jar --jars /usr/share/java/mysql-connector-java-8.2.0.jar /home/rachana/Stream-Processing-and-Batch-Processing-Using-Streaming-Spark-and-Kafka/consumer_batch.py

/*******************************
{
    wanna see the topics in kafka : ./bin/kafka-topics.sh --bootstrap-server localhost:9092 --list
    to delete topics: ./bin/kafka-topics.sh --bootstrap-server localhost:9092 --delete --topic <topic_name>
}
*************************************/
